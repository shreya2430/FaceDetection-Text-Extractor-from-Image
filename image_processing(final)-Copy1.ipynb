{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter,ImageEnhance\n",
    "import pytesseract\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Users/91987/AppData/Local/Tesseract-OCR/tesseract'\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='C:/Users/91987/Pictures/Saved Pictures/WhatsApp Image 2020-10-08 at 8.41.43 PM.jpeg'\n",
    "image=Image.open('stud_img.png')\n",
    "image1=Image.open(\"dog.png\")\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image=image.convert(\"RGB\")\n",
    "image1=image1.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "Image_Filters = [\"BLUR\",\"CONTOUR\",\"SMOOTH\",\"SHARPEN\",\"EDGE_ENHANCE\",\"GaussianBlur\",\"EMBOSS\",\"MinFilter\",\n",
    "                \"UnsharpMask\",\"EDGE_ENHANCE_MORE\"]\n",
    "#help(ImageFilter)\n",
    "for i,j in enumerate(Image_Filters):\n",
    "    print(i+1,\"->\",j)\n",
    "print(11,\"->\",\"For any random Filters\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(image.filter(random.choices([PIL.ImageFilter.BLUR,PIL.ImageFilter.CONTOUR,PIL.ImageFilter.SMOOTH,PIL.ImageFilter.SHARPEN])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(ImageFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY DIFFERENT FILTERS ON IMAGE(BY USER's CHOICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter your choice :\")\n",
    "print(\"#example: If you want to choose BLUR then type 1 and for CONTOUR type 2 and so on..\")\n",
    "# n=int(input())\n",
    "def Filteringfn(n):\n",
    "\n",
    "    if(n<=0 or n>11):\n",
    "        print(\"Sorry We Have only valid options for filters..try type between 1 to 11..\\n\")\n",
    "    if(n==11):\n",
    "        Filteringfn(random.randrange(0,9))\n",
    "    if(n==0):\n",
    "        im=image.filter(PIL.ImageFilter.BLUR)\n",
    "    if(n==1):\n",
    "        im=image.filter(PIL.ImageFilter.CONTOUR)\n",
    "    if(n==2):\n",
    "        im=image.filter(PIL.ImageFilter.SMOOTH)\n",
    "    if(n==3):\n",
    "        im=image.filter(PIL.ImageFilter.SHARPEN)\n",
    "    if(n==4):\n",
    "        im=image.filter(PIL.ImageFilter.EDGE_ENHANCE)\n",
    "    if(n==5):\n",
    "        im=image.filter(PIL.ImageFilter.GaussianBlur)\n",
    "    if(n==6):\n",
    "        im=image.filter(PIL.ImageFilter.EMBOSS)\n",
    "    if(n==7):\n",
    "        im=image.filter(PIL.ImageFilter.MinFilter)\n",
    "    if(n==8):\n",
    "        im=image.filter(PIL.ImageFilter.UnsharpMask)\n",
    "    if(n==9):\n",
    "        im=image.filter(PIL.ImageFilter.EDGE_ENHANCE_MORE) \n",
    "    if(n>=1 and n <=10):\n",
    "        display(im)\n",
    "\n",
    "n = int(input())\n",
    "Filteringfn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#im=image.filter(PIL.ImageFilter.BLUR)\n",
    "#im1=image1.filter(PIL.ImageFilter.CONTOUR)\n",
    "#display(im,im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE TO TEXT (USING PYTESSERACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "def image_text(path):\n",
    "    l=[]\n",
    "    im = Image.open(path)\n",
    "    text=pytesseract.image_to_string(im).replace('\\n',\" \")\n",
    "    l.append(text)\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Image.open(\"dog.png\"))\n",
    "print(image_text(\"dog.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_text(\"dog.png\"))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=Image.open(\"historical-newspapers.jpg\")\n",
    "display(im)\n",
    "print(image_text(\"historical-newspapers.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##able to return the position of each word(letter)\n",
    "#print(pytesseract.image_to_boxes(Image.open('historical-newspapers.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get verbose data including boxes, confidences, line and page numbers\n",
    "##print(pytesseract.image_to_data(Image.open('historical-newspapers.jpg')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a searchable PDF\n",
    "pdf = pytesseract.image_to_pdf_or_hocr('historical-newspapers.jpg', extension='pdf')\n",
    "with open('historical-newspapers.pdf', 'w+b') as f:\n",
    "    f.write(pdf) # pdf type is bytes by default\n",
    "\n",
    "# Get HOCR output\n",
    "hocr = pytesseract.image_to_pdf_or_hocr('historical-newspapers.jpg', extension='hocr')\n",
    "\n",
    "# Get ALTO XML output\n",
    "xml = pytesseract.image_to_alto_xml('historical-newspapers.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FACE DETECTION OF AN GIVEN IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(path):\n",
    "    \n",
    "    img=cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    #cv_img_bin=cv2.threshold(gray,120,255,cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    #faces= face_cascade.detectMultiScale(cv_img_bin)\n",
    "    # Detects faces of different sizes in the input image \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.58, 6) \n",
    "    \n",
    "    for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)  \n",
    "        roi_gray = gray[y:y+h, x:x+w] \n",
    "        roi_color = img[y:y+h, x:x+w] \n",
    "  \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EYES DETECTION OF AN GIVEN IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_detection(path):\n",
    "    img=cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.98, 4) \n",
    "    \n",
    "    for (x,y,w,h) in faces: \n",
    "        roi_gray = gray[y:y+h, x:x+w] \n",
    "        roi_color = img[y:y+h, x:x+w]   \n",
    "        # Detects eyes of different sizes in the input image \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.03,8)  \n",
    "  \n",
    "        #To draw a rectangle in eyes \n",
    "        for (ex,ey,ew,eh) in eyes: \n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2) \n",
    "            \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection('C:/Users/91987/Pictures/Saved Pictures/WhatsApp Image 2020-10-08 at 8.41.43 PM.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_detection(\"stud_img.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection(\"the indian_women_cricket_team.jpg\")\n",
    "eye_detection(\"the indian_women_cricket_team.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING FACE AND EYE DETECTION ON A ZIP FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TESTING FACE AND EYE DETECTION ON A ZIP FOLDER\n",
    "im=os.listdir(\"images/\")\n",
    "#images=[]\n",
    "for i in im:\n",
    "    #img = Image.open(str(\"images/\"+i))\n",
    "    img=cv2.imread(str(\"images/\"+i))\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #detect faces \n",
    "    faces=face_cascade.detectMultiScale(gray,1.35,4)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = img[y:y+h,x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for x1,y1,w1,h1 in eyes:\n",
    "            cv2.rectangle(roi_color,(x1,y1),(x1+w1,y1+h1),(0,127,255),2)\n",
    "    display(Image.fromarray(img))\n",
    "    im=os.listdir(\"images/\")\n",
    "#images=[]\n",
    "for i in im:\n",
    "    #img = Image.open(str(\"images/\"+i))\n",
    "    img=cv2.imread(str(\"images/\"+i))\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #detect faces \n",
    "    faces=face_cascade.detectMultiScale(gray,1.35,4)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = img[y:y+h,x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for x1,y1,w1,h1 in eyes:\n",
    "            cv2.rectangle(roi_color,(x1,y1),(x1+w1,y1+h1),(0,127,255),2)\n",
    "    display(Image.fromarray(img))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face+eyes detection using webcam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    ret,img=cap.read()\n",
    "    \n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #detect faces \n",
    "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = img[y:y+h,x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for x1,y1,w1,h1 in eyes:\n",
    "            cv2.rectangle(roi_color,(x1,y1),(x1+w1,y1+h1),(0,127,255),2)\n",
    "    cv2.imshow(\"image\",img)\n",
    "    \n",
    "       # Wait for Esc key to stop \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: \n",
    "        break\n",
    "\n",
    "  \n",
    "  \n",
    "cap.release() \n",
    "  \n",
    "# De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if a string is  in a image and if it is present then print a grid of all faces in that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## opening the folder and make a local_list in which image and the text of image is store and the store the local_list into\n",
    "## the global_list.\n",
    "\n",
    "pages_list=os.listdir('images/')\n",
    "\n",
    "Global_list=[]\n",
    "for page_name in pages_list:\n",
    "    local_list=[] \n",
    "    \n",
    "    #local list = [ page_name , tesseract_text ] \n",
    "    \n",
    "    local_list.append(page_name)\n",
    "    img = Image.open('images/'+page_name)\n",
    "    \n",
    "    local_list.append(pytesseract.image_to_string(img).replace('-\\n',''))\n",
    "\n",
    "    Global_list.append(local_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## search for a text and displaying the faces\n",
    "\n",
    "def search(text,folder):\n",
    "    for local_list in Global_list:\n",
    "        if text in local_list[1]:\n",
    "            print('Results found in file',local_list[0])\n",
    "            \n",
    "            try:\n",
    "                img = Image.open(str(folder+local_list[0]))\n",
    "                \n",
    "                faces = (face_cascade.detectMultiScale(np.array(img),1.35,4)).tolist()\n",
    "#                 storing the bounding boxes of all faces detected in each image of iteration\n",
    "                faces_in_each = []\n",
    "                \n",
    "                for x,y,w,h in faces:\n",
    "                    faces_in_each.append(img.crop((x,y,x+w,y+h)))\n",
    "#                     modifying local data structure in each iteration to sotre PIL Image of each face\n",
    "#                     display((img.crop((x,y,x+w,y+h))).resize((110,110)))\n",
    "                \n",
    "                contact_sheet = Image.new(img.mode, (550,110*int(np.ceil(len(faces_in_each)/5))))\n",
    "#                 contact sheet modification to display each iteration's result\n",
    "                x = 0\n",
    "                y = 0\n",
    "\n",
    "                for face in faces_in_each:\n",
    "                    face.thumbnail((110,110))\n",
    "#                   \n",
    "                    contact_sheet.paste(face, (x, y))\n",
    "                    \n",
    "                    if x+110 == contact_sheet.width:\n",
    "                        x=0\n",
    "                        y=y+110\n",
    "                    else:\n",
    "                        x=x+110\n",
    "                        \n",
    "                display(contact_sheet)\n",
    "            except:\n",
    "                print('But there were no faces in that file!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing \n",
    "\n",
    "search(\"Christopher\",'images/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
